<a name="hNbzi"></a>
# 基础篇
<a name="PkDTS"></a>
## 1高并发系统设计：他的通用设计方法是什么？
<a name="GcWRU"></a>
### 三种思路：
扩容：横向扩容，竖向扩容<br />缓存：Reids内存缓存，OSCache缓存等等<br />异步：异步返回结果，如NIO，AIO，消息回调等。<br />归根结底一句话：<br />高并发系统的演进应该是循序渐进，以解决系统中存在的问题为目的和驱动力的。不是一蹴而就的。

<a name="M0o11"></a>
## 2架构分层：为什么要分层？
避免大量代码纠缠一起，出现逻辑不清楚，模块之间相互依赖，拓展性差等问题。
<a name="vnIwT"></a>
### 什么是MVC分层架构？ 好处是什么？

- M：数据模型，V：视图层，C：控制层
- 将用户视图和业务处理隔离开，并且通过控制器连接起来，很好地实现了表现和逻辑的解耦，是一种标准的软件分层架构。
<a name="H9BwY"></a>
### 按照整体架构分为哪几层？

1. 表现层：最靠近用户，或者接口层。
1. 逻辑层：处理负责业务逻辑的Service层。
1. 数据层：处理和存储数据的Mapper交互层。
<a name="Seg6L"></a>
### 分层的好处？

1. 可以简化系统设计，对每一层有转专门的作用。
1. 可以实现复用。
1. 方便横向拓展。
<a name="yy5DV"></a>
### 分层架构的不足
增加了代码的复杂度，，增加了维护成本，多层之间网络交互会有性能损耗。
<a name="HwJ5W"></a>
### 阿里分层规约
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645277518267-b06293e7-3271-4c2d-99c0-dba801b3244c.png#clientId=u6c40793a-a6d8-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=303&id=u71e355ba&margin=%5Bobject%20Object%5D&name=image.png&originHeight=532&originWidth=469&originalType=binary&ratio=1&rotation=0&showTitle=false&size=137306&status=done&style=none&taskId=u59389998-70f7-45ea-8751-76e699c9deb&title=&width=267.5)

- 终端显示层：各端模板渲染并执行显示的层。主要是 Velocity 渲染，JS 渲染， JSP渲染，移动端展示等。
- 开放接口层：将 Service 层方法封装成开放接口，同时进行网关安全控制和流量控制等。Web 层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。
- Service 层：业务逻辑层。
- Manager 层：通用业务处理层。这一层主要有两个作用，其一，你可以将原先 Service层的一些通用能力下沉到这一层，比如与缓存和存储交互策略，中间件的接入；其二，你也可以在这一层封装对第三方接口的调用，比如调用支付服务，调用审核服务等。
- DAO 层：数据访问层，与底层 MySQL、Oracle、Hbase 等进行数据交互。外部接口或第三方平台：包括其它部门 RPC 开放接口，基础平台，其它公司的 HTTP 接口。
<a name="vPGlQ"></a>
### 补充：开发三大原则
<a name="cjRMx"></a>
#### 单一职责原则
规定每个类只有单一的功能，每一层拥有单一职责，且层与层之间边界清晰；
<a name="CfTdP"></a>
#### 迪米特法则
原意是一个对象应当对其它对象有尽可能少的了解，在分层架构的体现是数据的交互不能跨层，只能在相邻层之间进行
<a name="iOU8t"></a>
#### 开闭原则
要求软件对扩展开放，对修改关闭。它的含义其实就是将抽象层和实现层分离，抽象层是对 实现层共有特征的归纳总结，不可以修改，但是具体的实现是可以无限扩展，随意替换的。

<a name="iotUt"></a>
## 3系统设计目标一：系统怎样优化成高性能？
<a name="NmjRl"></a>
### 高并发系统设计三大目标：
高可用，高性能，可拓展。
<a name="ITH9Q"></a>
### 性能优化原则

1. 以解决问题为导，不能盲目的过度设计。
1. 遵循“二八法则”，先去优化主要的性能瓶颈点
1. 量化优化的指标，要时刻了解优化后对系统性能提高了多少QPS等。
1. 持续优化的过程，相对复杂的系统一般是慢慢优化，要持续，不要一蹴而就。
<a name="mB2cl"></a>
### 性能的度量指标
平均值：比如一段时间内所有响应时间相加，然后除以请求次数，则的得到平均响应时间。<br />最大值：查看最长响应时间的接口是多少。<br />分位值：分位值越大，对于慢请求的影响就越敏感。一般请求控制在200ms内，用户无感知的。
<a name="plxV7"></a>
### 高并发下的性能优化的两种思路
1.提高系统处理核心数<br />2.减少单次任务的响应时间

<a name="rZbLv"></a>
## 4系统设计目标二：系统怎样做到高可用？
高可用性（High Availability，HA）：指的是系统具备较高的无故障运行的能力。
<a name="sBABx"></a>
### 可用性的度量指标

1. MTBF：表示发生两次故障的间隔时间，时间越长代表越稳定。
1. MTTR：故障恢复时间，时间越短，影响最小，代表越稳定。
<a name="FwYBP"></a>
### 高可用系统设计思路
<a name="jIZKM"></a>
#### 1.系统设计层面

1. 故障转移：完善系统的主备切换，节点自动伸缩等。
1. 超时控制：收集系统之间的平均响应时间，降低超时请求的风险。
1. 降级：保证核心服务的稳定，二牺牲非核心服务的做法。
1. 限流：通过对并发请求做限流保护系统和数据库等。
<a name="swtyL"></a>
#### 2.系统运维层面

1. **灰度发布：**

减少发版时的故障，系统的变更不是一次性的推到线上，采用比例逐步发版。比如我们有100个节点，我们现在10%的节点上进行变更，减少影响，观察指标，防止出现大量错误。

2. **故障演练**

随件关闭部分节点来演练故障，提高恢复系统的速度。

<a name="uS4JE"></a>
## 5系统设计目标三：如何让系统高拓展？
数据库，缓存，第三方接口，负载均衡，交换机带宽等等都是需要考虑的影响！
<a name="gwz1f"></a>
### 高拓展的设计思路：
拆分：将复杂问题简单化。   
<a name="CSrsn"></a>
#### 1.存储层的拓展
首先考虑按照业务维度做拆分，提高并发。<br />其次考虑按照数据特征做水平拆分，比如分库分表，读写分离等。<br />最后尽量减少，事务的使用，分布式事务等耗时操作。
<a name="rCEV3"></a>
#### 2.业务层的拓展
一般从三个维度考虑业务层的拆分。<br />1.业务维度	2.重要性维度	3.请求来源维度

<a name="zY2JT"></a>
## 6面试现场第一期
当面试官问到组件实现原理时，目的是知道你是否了解底层的原理，在运用时针对底层能否合理的设计方案，以及组件出现问题是，是否有解决思路。

<a name="QIBN6"></a>
# 数据库篇
<a name="wPNDG"></a>
## 7池化技术：如何减少频繁创建数据库连接的损耗？

- 每次请求数据库，都要经历连接，校验等工作，影响性能。
- 连接池参数配置经验（最小连接控制在10个左右，最大控制再20-30左右）
- 设计思想：池化技术，它的核心思想是空间换时间，期望使用预先创建好的对象来减少频繁创建对象的性能开销，同时还可以对对象进行统一的管理，降低了对象的使用的成本。
<a name="DrcS9"></a>
### 数据库连接池的三个参数
1.最小连接数 （min）	2.最大连接数  (max)		3.请求超时时间 (time)
<a name="SuxLQ"></a>
### 连接池的流程 

1. 如果 min = 0，则创建连接，执行查询。
1. 如果使用量< min数，则利用空闲线程线程，执行查询。
1. 如果使用量> min，则创建连接线程，执行查询。
1. 如果使用量 >max，则等待释放出空闲线程，如果等待时间>time，则会抛出超时异常。
<a name="Ssz85"></a>
### 数据库连接池中是如何判断数据库是否可用的？

- 因为可能数据库节点发生了IP，或者端口改变，则会不可用。
- 所以C3P0这种连接池内部会定时发送一个 “select 1” 的指令，判断数据库是否可用。
<a name="Q5B2a"></a>
### 线程池的提交步骤：
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645282518728-e574ba23-12c9-4051-bfe6-ec68c32472ef.png#clientId=u6c40793a-a6d8-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=241&id=u97dfedbd&margin=%5Bobject%20Object%5D&name=image.png&originHeight=482&originWidth=677&originalType=binary&ratio=1&rotation=0&showTitle=false&size=170167&status=done&style=none&taskId=ud74016a0-feaa-4d72-a8a8-d83cff51a77&title=&width=338.5)<br />线程池常见的问题，和使用规范这里就不多BB了。

<a name="ERjda"></a>
## 8数据库优化方案一：查询增加时，如何主从分离?
主从读写分离<br />将查询和修改分离，提高单个实例的性能。<br />主从读写的两个技术关键点<br />1.数据的主从复制的实现？<br />2.如何屏蔽主从分离带来的访问方式上的变化？（如何实现读写分离访问数据库）

主从复制

- 依赖于binLog日志，创建一个log dump线程将binLig日志，同步到从库，从库接收到binLog日志后，写入到relayLog日志文件,最终实现主从一致。
- 并不是从库越多越好，因为主库需要创建多个logDump线程来处理复制请求，会影响性能，一般最多挂载3-5个从库足够了。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645284522165-d10fd366-83a0-4c73-9e25-6386145e014c.png#clientId=u6c40793a-a6d8-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=231&id=uc056401e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=289&originWidth=630&originalType=binary&ratio=1&rotation=0&showTitle=false&size=120065&status=done&style=none&taskId=ua69bc0b5-cc29-4453-85b3-b638c7f46c0&title=&width=503)<br />解决主从延迟的常见方案？<br />1.直接冗余数据：比如在发送消息时直接把下游所需要的信息发过去，避免二次查询。<br />2.使用缓存：写入从库之后，同时也写入到Redis中，然后下游直接从缓冲中取值。<br />3.直接查询主库：一般可以直接在SQL上标记直接查询主库。（慎用，避免压力问题）

主从延迟问题排查时，可能会遇到从库查询不到数据，过一阵子就又能查询到数据了，会有这样的诡异问题，这个一般可以做监控，当主从延时超过1S就需要告警。

2.如何实现读写分离访问数据库？<br />1.客户端层的分离：比如TDDL（阿里的），DDB（网易的），ShardJDBC，移植在业务系统里，比较简单。<br />2.服务端层的分离：比如MyCat等服务转发层，根据SQL标准语法来识别。（节点中心化）

<a name="gKHvO"></a>
## 9数据库优化方案二：写入增加时，如何实现分库分表？
<a name="JRoM3"></a>
### 如何对数据库做垂直拆分？

- 也就是将数据库的表拆分到多个不同的数据库中，拆分原则一般是按照业务类型拆分。
- 转库专用，故障隔离。
<a name="IcIm9"></a>
### 如何对数据库做水平拆分？
1.按照字段做Hash值拆分，比如用户ID取模。<br />2.按照字段的区间拆分，比如时间，地区等拆分。
<a name="Qw7Lw"></a>
### 分库分表带来的问题？
<a name="TLdFN"></a>
#### 1.引入了分表键，也叫分区键。
无论是哈希拆分还是区间拆分，之后所有的查询都需要带上这个字段，才能找到对应的库，那么查询的性能会很差。<br />合适的解决思路: <br />比如用的UserID作为一个拆分，需要根据昵称查询时，可以单独弄一个 昵称&UserID 的隐射表，拿到ID之后再去分表里面查询，这样节省空间又能减少无效查询。
<a name="upEkq"></a>
#### 2.无法做Join，和count统计查询
合适的解决思路：<br />先分开查询到内存里，然后在业务代码里做筛选。<br />把统计值实时维护到Redis缓存中。

<a name="Xwt2z"></a>
## 10发号器：如何保证分库分表后ID的全局唯一性？
<a name="EkMkU"></a>
### 分库分表示主键如何选择？
1.使用业务字段作为主键，比如手机号，身份证等。<br />2.生成ID唯一键。
<a name="GzgWv"></a>
### 生成全局唯一键的两种方式
<a name="dzxto"></a>
#### 1.业务代码里生成
直接在业务系统里去生成，不需要网络传输，依赖机器ID的唯一性生成。<br />另外，由于业务服务器的数量很多，很难保证机器 ID 的唯一性，所以需要引入 ZooKeeper 等分布式一致性组件来保证每次机器重启时都能获得唯一的机器ID。<br />常见的，雪花算法，Redis自增ID等等。
<a name="PZ487"></a>
#### 2.独立部署的ID发号器
需要单独部署一个节点<br />另外，如果请求发号器的 QPS 不高，比如说发号器每毫秒只发一个 ID，就会造成生成 ID的末位永远是 1，那么在分库分表时如果使用 ID 作为分区键就会造成库表分配的不均匀。
<a name="BsRIw"></a>
## 11NoSQL：高并发场景下：数据库和NoSQL如何做到互补？
NoSQL 数据库在性能、扩展性上的优势，以及它的一些特殊功能特性，主要有以下几点：<br />1. 在性能方面，NoSQL 数据库使用一些算法将对磁盘的随机写转换成顺序写，提升了写的性能；<br />2. 在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要 NoSQL 数据库的支持；<br />3. 在扩展性方面，NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性。

NoSQL 可供选型的种类很多，每一个组件都有各自的特点。你在做选型的时候需要对它的实现原理有比较深入的了解，最好在运维方面对它有一定的熟悉，这样在出现问题时才能及时找到解决方案。

<a name="eztjO"></a>
# 缓存篇
<a name="wdL7I"></a>
## 12缓存：遇到数据库瓶颈后，动态数据的查询如何加速？
什么是缓存？<br />什么是缓存区？
<a name="txCJr"></a>
### 缓存的分类?
<a name="uJB48"></a>
#### 1.静态缓存
Nginx，CDN，七牛等，静态存储的。
<a name="k945T"></a>
#### 2.分布式缓存	
Redis，MongoDB等。
<a name="MnN7U"></a>
#### 3.热点本地缓存？
HashMap，SpringCache等等。

<a name="uugQ7"></a>
## 13缓存使用姿势一：如何选择读写策略？
<a name="h58YA"></a>
### 读写缓存的三种策略
<a name="d8pjw"></a>
#### 旁路缓存策略（Cache Aside ）-常用的做法
说白了就是，先更新数据库，然后删除缓存，读取的时候查询数据库在把数据同步到缓存中。<br />存在的问题：<br />1.有可能存在如下并发错误，但是一般不存在，因为更新缓存比更新数据库快。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645291087334-e21bf6c9-0918-4031-8103-01f9a5a29f23.png#clientId=u6c40793a-a6d8-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=198&id=u579308e6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=321&originWidth=629&originalType=binary&ratio=1&rotation=0&showTitle=false&size=71909&status=done&style=none&taskId=u9972030c-e154-44c3-87be-6657a4d862b&title=&width=388.5)<br />2.如果是对缓存命中率有要求的场景，或者注册用户的场景，需要考虑立马读取的场景，这个时候需要在更新数据库后，立马更新缓存，这个时候可以考虑在二者上添加一个分布式锁。或者针对缓存添加一个过期时间，让错误缓存尽快过期。
<a name="pN2d4"></a>
#### 读穿/写穿式缓存策略
Read Through 策略就简单一些，它的步骤是这样的：先查询缓存中数据是否存在，如果<br />存在则直接返回，如果不存在，则由缓存组件负责从数据库中同步加载数据。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645291346912-e38673e8-c5d5-4597-b2d4-41f7326a14f8.png#clientId=u6c40793a-a6d8-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=251&id=u22f74367&margin=%5Bobject%20Object%5D&name=image.png&originHeight=501&originWidth=611&originalType=binary&ratio=1&rotation=0&showTitle=false&size=128279&status=done&style=none&taskId=ubef19ab6-ab13-4a21-84a4-7fdba9c6bba&title=&width=305.5)
<a name="HaRMN"></a>
#### 写回策略（Write Back）
这个策略的核心思想是在写入数据时只写入缓存，并且把缓存块儿标记为“脏”的。而脏块只有被再次使用时才会将其中的数据写入到后端存储中。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645291419436-2b19ce70-c881-4692-99bb-6c4b7d08df2e.png#clientId=u6c40793a-a6d8-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=311&id=u1d0261e6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=515&originWidth=513&originalType=binary&ratio=1&rotation=0&showTitle=false&size=100603&status=done&style=none&taskId=u5f62a9e2-5828-4723-aeb5-abf9dcb9350&title=&width=309.5)

<a name="Xm0Zw"></a>
## 14缓存使用姿势二：缓存如何做到高可用？
<a name="FWwJL"></a>
### 分布式缓存的高可用方案
<a name="VqXao"></a>
#### 客户端方案
在客户端配置多缓存节点，通过缓存写入和读取算法策略来实现分布式，提高缓存的可用性。<br />写数据时做数据分片，发送到不同节点上。<br />读数据时，利用多组缓存来容错，比如主从多副本机制。
<a name="PTd9u"></a>
#### 中间代理层方案
是在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层，而代理层中会内置高可用策略，帮助提升缓存系统的高可用。 ；例如Codis
<a name="o6kXo"></a>
#### 服务端方案
就是 Redis 2.4 版本后提出的 Redis Sentinel （哨兵机制）方案。
<a name="c8yAl"></a>
### Redis的分区算法，以及问题
哈希算法<br />在增加，或者删减节点的时候，需要重新数据迁移，不利于拓展。<br />一致性哈希算法<br />大概意思就是，在hash算法上对集群IP做一个圆环映射，保证在节点删减时无影响。<br />但是可能存在数据倾斜问题，这个可以 在上面增加虚拟节点解决该问题。

<a name="eNeXA"></a>
## 15缓存的使用姿势三：缓存穿透了咋办？
缓存穿透常见解决方案：<br />1.回种空值。<br />可能会存在数据库查询异常而返回空值，此时会误判为空值=不存在，所以最好设置一个过期时间。<br />2.使用布隆过滤器。<br />1. 判断元素是否存在时，有一定错误几率的，但是有可能出现假存在情况。<br />2. 不支持删除元素。 （可以把V值设置为累加，而不是仅仅存0，1,类似实现有布谷鸟过滤器）<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645293263384-8160242c-b9bc-45ea-a7ab-a5e9799ee5c4.png#clientId=u6c40793a-a6d8-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=234&id=u055c6323&margin=%5Bobject%20Object%5D&name=image.png&originHeight=380&originWidth=641&originalType=binary&ratio=1&rotation=0&showTitle=false&size=89428&status=done&style=none&taskId=u5af3ded2-3ee2-4aea-961b-bc939027f75&title=&width=395.5)<br />缓存的狗桩效应（dog-pile effect）- 击穿<br />比方说当有一个极热点的缓存项，它一旦失效会有大量请求穿透到数据库，这会对数据库造成瞬时极大的压力，我们把这个场景叫做“dog-pile effect”（狗桩效应）。 <br />解决：<br />1.利用分布式锁，只有获取到锁的请求才能够穿透到数据库。<br />2.后台定时线程维护缓存的更新。
<a name="sMutN"></a>
## 16CDN：每天亿级别静态资源请求如何加速？
静态资源加速的考虑点：就近访问原则
<a name="J71IP"></a>
### CDN的关键技术
CDN 就是将静态的资源分发到，位于多个地理位置机房中的服务器上，因此它能很好地解决数据就近访问的问题，也就加快了静态资源的访问速度。
<a name="PHXSA"></a>
### 搭建一个 CDN 系统需要考虑哪两点：
<a name="fS0OV"></a>
#### 1. 如何将用户的请求映射到 CDN 节点上；
依靠域名映射动态IP，寻找到CDN节点上。<br />通过预加载DNS方式，提前解析到CDN对应的IP地址，提高性能。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645294300064-20d7ba30-7bda-4926-adea-f94a7feefd64.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=193&id=u52d92dbf&margin=%5Bobject%20Object%5D&name=image.png&originHeight=385&originWidth=570&originalType=binary&ratio=1&rotation=0&showTitle=false&size=96750&status=done&style=none&taskId=u326ef357-34e2-4515-8200-90580c7c84f&title=&width=285)
<a name="kv6bj"></a>
#### 2. 如何根据用户的地理位置信息选择到比较近的节点。
GSLB（全局负载均衡）：保证流量均匀分配，和查找最近服务节点。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645294287357-d030a196-3f0e-4d7f-b21f-8ca5879be6d1.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=211&id=uf909a397&margin=%5Bobject%20Object%5D&name=image.png&originHeight=422&originWidth=620&originalType=binary&ratio=1&rotation=0&showTitle=false&size=121702&status=done&style=none&taskId=u89dd453a-7172-43a4-ad5f-6b19df7e19a&title=&width=310)
<a name="Pk0EC"></a>
### 总结：
1.DNS 技术是 CDN 实现中使用的核心技术，可以将用户的请求映射到 CDN 节点上；<br />2.DNS 解析结果需要做本地缓存，降低 DNS 解析过程的响应时间；<br />3.GSLB 可以给用户返回一个离着他更近的节点，加快静态资源的访问速度。

<a name="kr9VV"></a>
## 加餐-数据的迁移如何做？
<a name="Y2B7n"></a>
### 迁移考虑的点：

1. 迁移时不影响业务，能正常读写
1. 数据保证完整性，新旧库一致
1. 迁移过程可以回滚
<a name="dlYOc"></a>
### “双写”方案

1. 新库配置为源库的从库。如果是分库分表的话可以采用Canal把BinLog日志同步到新表里。
1. 写入旧库的时候，也要写入新库，如果写入新库失败则要把它记录到日志表中，后续处理。
1. 校验数据，可以采用统计全局，或者抽样等来验证是否完整。
1. 流量切换到新库，担心一次性切换会有问题，可以采用灰度发布，慢慢迁移过来。
1. 回滚问题，如果遇到异常可以立马回滚到老库。最好采用动态化的配置。
1. ![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645295063638-f6e90e3b-6ebf-4557-a1e1-d40ac1eb1649.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=347&id=u9901fc1e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=517&originWidth=533&originalType=binary&ratio=1&rotation=0&showTitle=false&size=127876&status=done&style=none&taskId=udff93088-df06-4d97-8ad9-eee68f84c8c&title=&width=357.5)
<a name="tZprz"></a>
### 跨机房迁移到云上方案
需要考虑的一个重要的因素是：<br />自建机房到云上的专线的带宽和延迟，你需要尽量减少跨专线的读操作，所以在切换读流量的时候，你需要保证自建机房的应用服务器读取本机房的数据库，云上的应用服务器读取云上的数据库。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645295100568-19cef2f6-fc23-4454-b5df-dcd59f862556.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=320&id=u0735f543&margin=%5Bobject%20Object%5D&name=image.png&originHeight=452&originWidth=542&originalType=binary&ratio=1&rotation=0&showTitle=false&size=175046&status=done&style=none&taskId=u84427bb3-c622-4fee-8bd7-18328a0e0e1&title=&width=384)
<a name="yTsl2"></a>
### 级联同步方案
比较适合数据从自建机房向云上迁移的场景。因为迁移上云，最担心云上的环境和自建机房的环境不一致，会导致数据库在云上运行时，因为参数配置或者硬件环境不同出现问题。<br />步骤：<br />我们会在自建机房准备一个备库，在云上环境上准备一个新库，通过级联同步的方式在自建机房留下一个可回滚的数据库，具体的步骤如下：<br />1. 先将新库配置为旧库的从库，用作数据同步；<br />2. 再将一个备库配置为新库的从库，用作数据的备份；<br />3. 等到三个库的写入一致后，将数据库的读流量切换到新库；<br />4. 然后暂停应用的写入，将业务的写入流量切换到新库（由于这里需要暂停应用的写入，所以需要安排在业务的低峰期）。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645295598280-77f09693-4cc0-4306-97f1-ddec73495854.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=271&id=u472c4431&margin=%5Bobject%20Object%5D&name=image.png&originHeight=406&originWidth=620&originalType=binary&ratio=1&rotation=0&showTitle=false&size=129158&status=done&style=none&taskId=u342b539e-02f3-4770-ab9f-ac5782f2d09&title=&width=414)<br />回滚方案也简单，可以先将读流量切换到备库，再暂停应用的写入，将写流量切换到备库，这样所有的流量都切换到了备库，也就是又回到了自建机房的环境，就可以认为已经回滚了。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645295626838-bc4a9b30-8fa8-4480-9df7-5b4efa2f9983.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=370&id=u6c4dbcfe&margin=%5Bobject%20Object%5D&name=image.png&originHeight=505&originWidth=565&originalType=binary&ratio=1&rotation=0&showTitle=false&size=134584&status=done&style=none&taskId=u56bde456-34bb-4bd5-a78f-09b81d82ca9&title=&width=413.5)
<a name="TPJOv"></a>
### 缓存迁移的重点：
缓存的迁移重点，是保证云上缓存的命中率，你可以使用改进版的副本组方式来迁移，在缓存写入的时候，异步写入云上的副本组，在读取时放少量流量到云上副本组，从而又可以迁移部分数据到云上副本组，又能尽量减少穿透给自建机房造成专线延迟的问题。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645295737131-7b32ef10-7e73-4200-a830-c3c09f3472f7.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=140&id=u91660f32&margin=%5Bobject%20Object%5D&name=image.png&originHeight=280&originWidth=610&originalType=binary&ratio=1&rotation=0&showTitle=false&size=99742&status=done&style=none&taskId=uda25dba8-0279-4e80-90cf-d4ac2382d8c&title=&width=305)<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645295750570-30bbb83c-0555-4a08-bf06-11091b23ec46.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=131&id=uf939b4c5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=262&originWidth=627&originalType=binary&ratio=1&rotation=0&showTitle=false&size=87329&status=done&style=none&taskId=u9d6ae84a-3604-4547-aa2a-9d28b6fe4f7&title=&width=313.5)

<a name="I4OwB"></a>
# 消息队列篇
<a name="lbft6"></a>
## 17消息队列：秒杀时如何处理每秒上万次的下单请求？
<a name="GCBlD"></a>
### 削峰填谷：秒杀场景下基于MQ削峰
将秒杀请求暂存在消息队列中，然后业务服务器会响应用户“秒杀结果正在计算中”，释放了系统资源之后再处理其它用户的请求。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645296182953-9fd5f378-71d1-40e8-91b3-c5a89b8199b2.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=121&id=u21126110&margin=%5Bobject%20Object%5D&name=image.png&originHeight=218&originWidth=629&originalType=binary&ratio=1&rotation=0&showTitle=false&size=74645&status=done&style=none&taskId=ub3691fa5-ef4c-424f-9f33-beb7a32fbd3&title=&width=350.5)
<a name="Y6MY2"></a>
### 异步处理：简化秒杀中的业务流程
秒杀场景下，会有主要的业务逻辑，有次要的业务逻辑：比如说，主要的流程是生成订单、扣减库存；次要的流程可能是我们在下单购买成功之后会给用户发放优惠券，会增加用户的积分。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645296272961-7b02fe9e-76b8-40b7-80aa-a6cfd6bd6484.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=100&id=u3aa75202&margin=%5Bobject%20Object%5D&name=image.png&originHeight=199&originWidth=654&originalType=binary&ratio=1&rotation=0&showTitle=false&size=64604&status=done&style=none&taskId=u7dd2d0a2-3908-47c2-9835-d7af3ff31a5&title=&width=327)
<a name="ITlCV"></a>
### 解耦：实现系统模块间的松耦合

   - 整体系统的耦合性比较强，当数据团队的接口发生故障时，会影响到秒杀系统的可用性。
   - 当数据系统需要新的字段，就要变更接口的参数，那么秒杀系统也要随着一起变更。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645296348464-91dc30d1-86cd-4b3f-8352-812084ed9c9e.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=108&id=uda02250d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=215&originWidth=651&originalType=binary&ratio=1&rotation=0&showTitle=false&size=83293&status=done&style=none&taskId=u13ea64bf-4134-4c55-a01b-67283179b19&title=&width=325.5)
<a name="nc4k4"></a>
#### 引入MQ后会使系统变得复杂，比如如何保证消费幂等性，可靠性，不丢失等问题。

<a name="i7tZ1"></a>
## 18消息投递：如何保证消息仅仅被消费一次？
<a name="KELXe"></a>
### 消息丢失的三个地方
生产者，消息队列，消费者
<a name="XR96P"></a>
### 1.生产过程中丢失
建议使用：消息重传机制，重试2-3次，但是可能会出现重复发送问题。
<a name="dq5de"></a>
### 2.消息队列中丢失
建议开启队列的异步刷盘机制，持久化到磁盘。<br />或者采用集群，多副本模式保证尽量不丢失。
<a name="HGZmJ"></a>
### 3.消费者丢失
建议开启重复消费，但是要保证幂等性<br />在消息被生产的时候，使用发号器给它生成一个全局唯一的消息 ID，消息被处理之后，把这个 ID 存储在数据库中，在处理下一条消息之前，先从数据库里面查询这个全局 ID 是否被消费过，如果被消费过就放弃消费。
<a name="PEdCu"></a>
#### 利用CAS乐观锁实现幂等消费
生产者先查询消费者那端的版本号，然后连同消息和版本一起发送过去，消费的时候先判断一下版本是否正确，否则就不与消费。  （但是会不会有顺序问题呢？）

<a name="NxX1a"></a>
## 19消息队列：如何降低消息队列系统中的延迟问题？
增加消息延时监控
<a name="eC1mN"></a>
### 减少消息延迟的方案
从 消费者 和 生产者 两个维度去完成

1. 优化消费代码提升性能；
1. 增加消费者的数量（这个方式比较简单）
<a name="yMpVK"></a>
### 什么是零拷贝技术？
<a name="Jui8s"></a>
#### 正常4次拷贝流程
1. 数据从磁盘拷贝到内核缓冲区；<br />2. 系统调用将内核缓存区的数据拷贝到用户缓冲区；<br />3. 用户缓冲区的数据被写入到 Socket 缓冲区中；<br />4. 操作系统再将 Socket 缓冲区的数据拷贝到网卡的缓冲区中。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645298856127-5c8986d9-bff4-4ffb-8d99-ca0e95a840e6.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=119&id=u740ecc80&margin=%5Bobject%20Object%5D&name=image.png&originHeight=238&originWidth=596&originalType=binary&ratio=1&rotation=0&showTitle=false&size=70798&status=done&style=none&taskId=ufbb4e270-d57c-4bb5-b5e5-7659a5ae11f&title=&width=298)
<a name="XWfsL"></a>
#### 零拷贝流程

1. 操作系统提供了 Sendfile 函数，可以减少数据被拷贝的次数。
1. 使用了 Sendfile 之后，在内核缓冲区的数据不会被拷贝到用户缓冲区，而是直接被拷贝到 Socket 缓冲区，节省了一次拷贝的过程，提升了消息发送的性能。
1. 高级语言中对于 Sendfile 函数有封装，比如说在Java 里面的 java.nio.channels.FileChannel 类就提供了 transferTo 方法提供了 Sendfile的功能。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645298865501-8b6be434-a0f4-492f-b797-d00457e580b7.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=147&id=u50671e28&margin=%5Bobject%20Object%5D&name=image.png&originHeight=293&originWidth=610&originalType=binary&ratio=1&rotation=0&showTitle=false&size=78889&status=done&style=none&taskId=u367b30f3-2016-4cb2-bed7-5b969e5921f&title=&width=305)
<a name="ML70D"></a>
### 切记！队列堆积问题
1.超时丢失消息<br />2.增加消费节点，提升消费节点效率。

<a name="wDBD4"></a>
## 20面试现场第二期
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645299081978-c6a309b9-6e10-4e28-bc26-f5cbaa530a29.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=268&id=u59c4f5fc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=535&originWidth=568&originalType=binary&ratio=1&rotation=0&showTitle=false&size=285089&status=done&style=none&taskId=uf816f310-0905-4b44-bed2-fa29940aac2&title=&width=284)<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645299144792-e029c255-ff57-4e31-b502-3ce7f3a339af.png#clientId=ue2419624-1301-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=439&id=uf125b10e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=878&originWidth=565&originalType=binary&ratio=1&rotation=0&showTitle=false&size=520805&status=done&style=none&taskId=u3ba7d06c-94df-4de2-85d2-d11a79deb2a&title=&width=282.5)
<a name="lbOf0"></a>
# 分布式服务篇
<a name="JMFzV"></a>
## 21系统架构：每秒1万次请求 的系统要做服务拆分吗？
实际业务中会基于什么样的考虑，对系统做微服务化拆分，其实，系统的 QPS 并不是决定性的因素。影响的因素，我归纳为以下几点：

1. 系统中，使用的资源出现扩展性问题，尤其是数据库的连接数出现瓶颈；
1. 大团队共同维护一套代码，带来研发效率的降低，和研发成本的提升；
1. 系统部署成本越来越高。

<a name="OlFwt"></a>
## 22微服务架构：微服务化后，系统架构要如何改造？
<a name="FhJ0V"></a>
### 微服务拆分的原则
<a name="OKDjx"></a>
#### 1.服务内部功能高内聚，低耦合。
尽量减少下游系统对上游系统的业务依赖。以防上游更改，下游也要变的问题。
<a name="MttNX"></a>
#### 2.服务拆分粒度。
尽量先粗后细，减少网络调用，提高效率。
<a name="TQj0Y"></a>
#### 3.拆分时不要影响正常业务迭代
尽量做到拆分的技术OKR和业务OKR同时进行，先尝试边角业务推行。
<a name="PU8Fq"></a>
#### 4.服务接口的定义要具备拓展性
在网络通信下，服务接口的定义要具有拓展性，例如接口返回枚举。
<a name="X2HS0"></a>
### 微服务化后带来的问题
1,服务接口化，需要 一个注册中心。<br />2.服务的依赖性增强，对性能会有影响、需要引入服务治理，限流，超时，降级等体系。<br />3.服务问题排查，链路追踪成为了问题。

<a name="VLt1n"></a>
## 23RPC框架：10QPS下如何实现毫秒级别的服务调用？
<a name="FVpgv"></a>
### 实现高并发 RPC 框架的三要素：
1. 选择高性能的 I/O 模型，这里我推荐使用同步多路 I/O 复用模型；<br />2. 调试网络参数，这里面有一些经验值的推荐。比如将 tcp_nodelay 设置为 true，也有一些参数需要在运行中来调试，比如接受缓冲区和发送缓冲区的大小，客户端连接请求缓冲队列的大小（back log）等等；<br />3. 序列化协议依据具体业务来选择。如对性能要求不高，可选择JSON，否则可选择Thrift和Protobuf其中之一。
<a name="hsISp"></a>
### 常见的五种I/O 模型：

1. 同步阻塞 I/O
1. 同步非阻塞 I/O
1. 同步多路 I/O 复用
1. 信号驱动 I/O
1. 异步 I/O
<a name="fk2ao"></a>
## 24注册中心：分布式系统如何寻址？
注册中心的基本功能<br />服务地址存储<br />存储内容发生变化，将变更内容推送到客户端<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645349128196-63689b71-3a7a-44fd-9416-22bd3625a48c.png#clientId=u4a986c71-fd21-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=168&id=uc12177a5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=335&originWidth=508&originalType=binary&ratio=1&rotation=0&showTitle=false&size=74622&status=done&style=none&taskId=ubfcc2728-cf78-4f7b-b614-fb4cb2a45aa&title=&width=254)
<a name="bnAZc"></a>
### 注册中心中怎么管理服务状态
<a name="jvDcl"></a>
#### 1.主动探测
直接向注册的节点发送请求，是否可用。<br />但是当注册节点一多，则会导致性能下降，和一些端口冲突问题。
<a name="tZxFu"></a>
#### 2.定时心跳模式
服务节点向注册中心定时发送心跳。
<a name="YrTpr"></a>
## 25分布式Trace：横跨几十个分布式组件的满请求要如何排查？
<a name="EVaQV"></a>
### 服务追踪需要满足两点：
1.代码无侵入，可以使用切面编程的方式解决 。<br />2.性能上要低损耗，建议采用静态代理和日志采样的方式，减少性能的影响。

无论是单体系统还是服务化架构，无论是服务追踪还是业务问题排查，你都需要在日志<br />中增加 requestId，这样可以将你的日志串起来，给你呈现一个完整的问题场景。

<a name="zgfio"></a>
## 26负载均衡：怎么提升系统的横向拓展能力？
<a name="Hfr6S"></a>
### 负载均衡服务器的两种类型
<a name="t9kpF"></a>
#### 1.代理类的负载均衡服务
比如：Nginx，LVS等
<a name="KNIBu"></a>
#### 2.客户端负载均衡服务
直接在客户端层面做负载转发。自定义一个策略。
<a name="bvY0E"></a>
### 负载均衡的策略：
负载均衡的策略可以优先选择动态策略，保证请求发送到性能最优的节点上；如果没有合适的动态策略，那么可以选择轮询的策略，让请求平均分配到所有的服务节点上。

<a name="fHLan"></a>
## 27API网关：系统的门面要作何选择？
1.API 网关分为入口网关和出口网关两类，入口网关作用很多，可以隔离客户端和微服<br />务，从中提供协议转换、安全策略、认证、限流、熔断等功能。出口网关主要是为调用<br />第三方服务提供统一的出口，在其中可以对调用外部的 API 做统一的认证、授权，审计<br />以及访问控制；

2.API 网关的实现重点在于性能和扩展性，你可以使用多路 I/O 复用模型和线程池并发处<br />理，来提升网关性能，使用责任链模式来提升网关的扩展性；

3.API 网关中的线程池，可以针对不同的接口或者服务做隔离和保护，这样可以提升网关<br />的可用性；

4.API 网关可以替代原本系统中的 Web 层，将 Web 层中的协议转换、认证、限流等功能<br />挪入到 API 网关中，将服务聚合的逻辑下沉到服务层。

<a name="PeAoG"></a>
## 28多数据中心：跨地域的分布式系统要如何做？
<a name="Fid0j"></a>
### 什么是多机房部署？
在不同的 IDC 机房中，部署多套服务，这些服务共享同一份业务数据，并且都可以承接来自用户的流量。
<a name="rttZF"></a>
### 多机房部署如何共享同一个业务数据库？（两种方案）
无论采用哪种方式都会存在数据延迟问题，尽量业务上规避。<br />一般国内跨机房延迟在50ms内，国外在200ms内。
<a name="NkgqD"></a>
#### 跨机房读取原库数据
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645352323761-f37b9db9-623a-4c41-860c-56f0da692f93.png#clientId=u4a986c71-fd21-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=214&id=u6dd27203&margin=%5Bobject%20Object%5D&name=image.png&originHeight=427&originWidth=484&originalType=binary&ratio=1&rotation=0&showTitle=false&size=84332&status=done&style=none&taskId=ue65150a3-95c8-4884-87a3-d767b5e9ba7&title=&width=242)
<a name="n5LZR"></a>
#### 跨机房读取从库的数据
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645352335049-798ff1c6-b0a0-4742-a58b-e36839334338.png#clientId=u4a986c71-fd21-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=188&id=u8f930e39&margin=%5Bobject%20Object%5D&name=image.png&originHeight=375&originWidth=523&originalType=binary&ratio=1&rotation=0&showTitle=false&size=92174&status=done&style=none&taskId=u5a5bba9c-bce8-405b-bdaa-b95dfa1ebdd&title=&width=261.5)

<a name="tKYLz"></a>
### 多机房部署方案的升级
<a name="zKasu"></a>
#### 1.同城双活
数据库的主库可以部署在一个机房中，比如部署在 A 机房中，那么 A 和 B 机房数据都会被写入到 A 机房中。然后，在 A、B 两个机房中各部署一个从库，通过主从复制的方式，从主库中同步数据，这样双机房的查询请求可以查询本机房的从库。一旦 A 机房发生故障，可以通过主从切换的方式，将 B 机房的从库提升为主库，达到容灾的目的。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645352929578-763b1db1-f541-4df2-a208-baf1bf862afc.png#clientId=u4a986c71-fd21-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=145&id=uc8438bf6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=290&originWidth=645&originalType=binary&ratio=1&rotation=0&showTitle=false&size=119437&status=done&style=none&taskId=uac510786-9b2a-455a-8b91-527cc0152a9&title=&width=322.5)
<a name="r7jIr"></a>
#### 2.异地双活
在考虑异地多活方案时，你首先要考虑异地机房的部署位置。它部署的不能太近，否则发生<br />自然灾害时，很可能会波及，所以可避免整个城市停电等灾难。
<a name="gZdk7"></a>
#### 异地双活：数据同步的方案有两种：
（一般建议二者同时使用）

1. 一种基于存储系统的主从复制，比如 MySQL 和 Redis。也就是在一个机房部署主库，在异地机房部署从库，两者同步主从复制, 实现数据的同步。
1. 另一种是基于消息队列的方式。一个机房产生写入请求后，会写一条消息到消息队列，另一个机房的应用消费这条消息后，再执行业务处理逻辑，写入到存储服务中。
1. ![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645353007901-a6299d45-e06b-40b2-a5e7-2e567c0e92ca.png#clientId=u4a986c71-fd21-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=138&id=uf1fa7a57&margin=%5Bobject%20Object%5D&name=image.png&originHeight=276&originWidth=611&originalType=binary&ratio=1&rotation=0&showTitle=false&size=112503&status=done&style=none&taskId=u37eed656-a82c-40de-92a1-1624bb825c1&title=&width=305.5)
<a name="m22Ix"></a>
## 29Service Mesh：如何屏蔽分布式系统的服务治理细节？
说白了，就是如果你的系统是微服务，但是其中有些系统是采用PHP写的，那么你要实现服务之间的调用，则需要依赖一个中间代理层，比如ServiceMesh 这种。
<a name="HcNCu"></a>
### 什么是ServiceMesh？

1. Service Mesh 分为数据平面和控制平面。数据平面主要负责数据的传输；控制平面用来控制服务治理策略的植入。出于性能的考虑，一般会把服务治理策略植入到数据平面中，控制平面负责服务治理策略数据的下发。
1. Sidecar 的植入方 式目前主要有两种实现方式，一种是使用 iptables 实现流量的劫持；另一种是通过轻量级客户端来实现流量转发。

<a name="h8Clb"></a>
# 维护篇
<a name="N4oXo"></a>
## 30给系统加上眼睛：怎么做服务监控？

- 监控指标选择
- 延迟，吞吐量，错误和饱和度

![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645370461935-ecf61729-b52e-4ada-be6c-9d55018775dd.png#clientId=u4a986c71-fd21-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=188&id=u4298fab6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=311&originWidth=626&originalType=binary&ratio=1&rotation=0&showTitle=false&size=169241&status=done&style=none&taskId=u501e66a9-49fb-4079-9f26-541ed05b1ed&title=&width=379)
<a name="dEng2"></a>
### 如何采集数据指标？
1.服务端代理获取统计信息<br />2.业务代码中埋点统计<br />3.日志数据分析

<a name="Wq3sT"></a>
### 监控数据的处理和存储方式？

- 解析日志数据等
- 对数据做一些聚合运算
- 将数据存储在时间序列数据库中，之后生成报表。
<a name="aZhEI"></a>
## 31应用性能管理：用户的使用体验应该如何监控？
如何实现到用户层面上的监控？实现端到端的监控
<a name="lp1DS"></a>
### 如何搭建APM（应用性能管理系统）？
1. 从客户端采集到的数据可以用通用的消息格式，上传到 APM 服务端，服务端将数据存入到 Elasticsearch 中，以提供原始日志的查询，也可以依据这些数据形成客户端的监控报表；<br />2. 用户网络数据是我们排查客户端，和服务端交互的重要数据，可以通过代码的植入，来获取到这些数据；<br />3. 无论是网络数据，还是异常数据，亦或是卡顿、崩溃、流量、耗电量等数据，你都可以通过把它们封装成 APM 消息格式，上传到 APM 服务端，这些用户在客户端上留下的踪迹可以帮助你更好地优化用户的使用体验。

<a name="a6rNg"></a>
## 32压力测试：怎样设计全链路压力测试平台？
<a name="ZROha"></a>
### 什么是压力测试?
高并发大流量下，进行测试，测试人员可通过峰值负载下，观察系统的稳定性。<br />全链路压测：针对真个链路执行压力测试，会把缓存，MQ，Redis，第三方调用等测试进去。
<a name="dJjAj"></a>
### 如何搭建全链路压测平台？
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645371342014-0ce5c69a-01f7-41bc-9015-103d56156e57.png#clientId=u4a986c71-fd21-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=172&id=u1c48d609&margin=%5Bobject%20Object%5D&name=image.png&originHeight=343&originWidth=607&originalType=binary&ratio=1&rotation=0&showTitle=false&size=129296&status=done&style=none&taskId=u7134a1c3-26d8-4e1f-8e89-deb4dc90ee4&title=&width=303.5)

<a name="o7n9C"></a>
## 33配置管理：成千上万的配置项要如何管理？
1.配置存储是分级的，有公共配置，有个性的配置，个性配置会覆盖公共配置，可减少存储配置项的数量；<br />2.配置中心可以提供配置变更通知的功能，可以实现配置的热更新；<br />3.配置中心关注的性能指标中，可用性的优先级是高于性能的，一般我们会要求配置中心的可用性达到 99.999%，甚至会是 99.9999%。

<a name="vtlKJ"></a>
## 34降级：如何屏蔽非核心系统故障的影响？
1.在分布式环境下最怕的是服务或者组件慢，因为这样会导致调用者持有的资源无法释放，最终拖垮整体服务。<br />2.服务熔断的实现是一个有限状态机，关键是三种状态之间的转换过程。<br />3.开关降级的实现策略主要有返回降级数据、降频和异步三种方案。

<a name="PpkkO"></a>
## 35流量控制：高并发系统中我们如何操纵流量？
什么是限流？
<a name="Puaqm"></a>
### 常见的限流算法？
<a name="PmbPn"></a>
#### 固定窗口算法
启动一个定时器重置技术，就相当于1秒只能访问十次，然后一秒后过期，但是在1.01秒这个邻接节点时可能出现突然19次请求进来。<br />![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645372666883-26533385-4e0e-42bf-9a18-be0443183b28.png#clientId=u4a986c71-fd21-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=122&id=u37ef06d9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=236&originWidth=638&originalType=binary&ratio=1&rotation=0&showTitle=false&size=44887&status=done&style=none&taskId=u9521e34c-4a68-4cb9-9950-ea8d331c4e9&title=&width=329)
<a name="naZow"></a>
#### 滑动窗口算法

- 原理是将时间的窗口划分为个小窗口，每个小窗口中都有单独的请求计数。
- 比如下面这张图，我们将 1s 的时间窗口划分为 5 份，每一份就是 200ms；那么当在 1s 和 1.2s 之间来了一次新的请求时，我们就需要统计之前的一秒钟内的请求量，也就是 0.2s～1.2s 这个区间的总请求量，如果请求量超过了限流阈值那么就执行限流策略。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645372729437-1cb37a30-c04b-4c55-ad80-795dc11bdd6b.png#clientId=u4a986c71-fd21-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=163&id=u543154af&margin=%5Bobject%20Object%5D&name=image.png&originHeight=294&originWidth=647&originalType=binary&ratio=1&rotation=0&showTitle=false&size=54761&status=done&style=none&taskId=uba138afe-5ca8-45da-bb3a-ed74c3d01d0&title=&width=358.5)
<a name="VSZ0S"></a>
#### 漏桶算法

- 漏桶算法的原理很简单，它就像在流量产生端和接收端之间增加一个漏桶，流量会进入和暂存到漏桶里面，而漏桶的出口处会按照一个固定的速率将流量漏出到接收端（也就是服务接口）。
- 一般使用消息队列作为漏桶的实现，流量首先被放入到消息队列中排队，由固定的几个队列处理程序来消费流量，如果消息队列中的流量溢出，后续的流量就会被拒绝。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/1461694/1645373059470-769d8a97-a7c1-4894-96be-6c760638a1b8.png#clientId=u4a986c71-fd21-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=265&id=u3d13bd6e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=530&originWidth=360&originalType=binary&ratio=1&rotation=0&showTitle=false&size=53933&status=done&style=none&taskId=u23765e05-76d2-46f9-a601-70ab4c763c3&title=&width=180)
<a name="VIFIC"></a>
#### 牌算桶算法

1. 需要在一秒内限制访问次数为 N 次，那么就每隔 1/N 的时间，往桶内放入一个令牌；
1. 在处理请求前先从桶中获得一个令牌，如桶中已没有令牌，那么就要等待新的令牌或者直接拒绝服务；
1. 桶中的令牌总数也要有一个限制，如果超过了限制就不能向桶中再增加新的令牌了。这样可以限制令牌的总数，一定程度上可以避免瞬时流量高峰的问题。
<a name="BMbgP"></a>
#### 总结：
更加倾向于令牌桶算法，因为在面对突发流量的时候，采用的解决方式是缓存在漏桶中， 这样流量的响应时间就会增长。令牌桶能够应对一定量的突发流量，而 Guava 中的限流方案就是使用令牌桶算法来实现的。


<a name="caVgV"></a>
## 36面试现场第三期
<a name="mRB72"></a>
# 实战篇
<a name="V7T31"></a>
## 37技术系统设计一：面对海量数据的计数器如何实现？
1.数据库 + 缓存的方案是计数系统的初级阶段，完全可以支撑中小访问量和存储量的存储服务。如果你的项目还处在初级阶段，量级还不是很大，那么你一开始可以考虑使用这种方案。<br />2.通过对原生 Redis 组件的改造，我们可以极大地减小存储数据的内存开销。<br />3.使用 SSD+ 内存的方案可以最终解决存储计数数据的成本问题。这个方式适用于冷热数据明显的场景，你在使用时需要考虑如何将内存中的数据做换入换出。
<a name="BH7QW"></a>
## 38技术系统设计二：50万QPS下如何设计未读数系统？
这三类需求虽然都和未读数有关，但是需求场景不同、对于量级的要求不同，设计出来的方案也就不同。因此，就像我刚刚提到的样子，你在做方案设计的时候，要分析需求的场景，比如说数据的量级是怎样的，请求的量级是怎样的，有没有一些可以利用的特点（比如系统通知未读场景下的有限共享存储、信息流未读场景下关注人数是有限的等等），然后再制定针对性的方案，切忌盲目使用之前的经验套用不同的场景，否则就可能造成性能的下降，甚至危害系统的稳定性。

<a name="MvmlH"></a>
## 39信息流设计一：通用信息流系统的推送模式如何做？
1.推模式就是在用户发送微博时，主动将微博写入到他的粉丝的收件箱中；<br />2.推送信息是否延迟、存储成本、方案可扩展性及针对取消关注和微博删除的特殊处理是推模式的主要问题；<br />3.推模式比较适合粉丝数有限的场景。

<a name="nd4LB"></a>
## 40信息流设计二：通用信息流系统的拉取模式如何做？

1. 在拉模式下，我们只需要保存用户的发件箱，用户的信息流是通过聚合关注者发件箱数据来实现的；
1. 拉模式会有比较大的聚合成本，缓存节点也会存在带宽的瓶颈，所以我们可以通过一些权衡策略尽量减少获取数据的大小，以及部署缓存副本的方式来抗并发；
1. 推拉结合的模式核心是只推送活跃的粉丝用户，需要维护用户的在线状态以及活跃粉丝的列表，所以需要增加多余的空间成本来存储，这个你需要来权衡。

拉模式和推拉结合模式比较适合微博这种粉丝量很大的业务场景，因为它们都会有比较可控<br />的消息推送延迟。
